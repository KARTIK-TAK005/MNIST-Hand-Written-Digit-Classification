{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f7e00c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hand digit classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71311134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a1917d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/7z/2ytgr4j16lg02zx_3cn2m5pc0000gn/T/ipykernel_14135/2375492955.py:4: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /var/folders/7z/2ytgr4j16lg02zx_3cn2m5pc0000gn/T/ipykernel_14135/2375492955.py:4: The name tf.logging.ERROR is deprecated. Please use tf.compat.v1.logging.ERROR instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#loading the dataset\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fc93b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"data/mnist\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf090713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of images in images training set (55000, 784)\n",
      "No of images in label training set (55000, 10)\n",
      "No of images in images test set (10000, 784)\n",
      "No of images in label test set (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#train-test split\n",
    "#training\n",
    "print(\"No of images in images training set {}\".format(mnist.train.images.shape))\n",
    "print(\"No of images in label training set {}\".format(mnist.train.labels.shape))\n",
    "#test\n",
    "print(\"No of images in images test set {}\".format(mnist.test.images.shape))\n",
    "print(\"No of images in label test set {}\".format(mnist.test.labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a0980d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f97ecbd9690>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img1 = mnist.train.images[0].reshape(28, 28)\n",
    "plt.imshow(img1, cmap = \"Reds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "450ed2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining number of neurons in layers\n",
    "num_input = 784\n",
    "num_hidden1 = 512\n",
    "num_hidden2 = 256\n",
    "num_hidden3 = 128\n",
    "num_output = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f75f7838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#placeholders\n",
    "with tf.name_scope('input'):\n",
    "    X = tf.placeholder(\"float\", [None, num_input])\n",
    "with tf.name_scope(\"output\"):\n",
    "    Y = tf.placeholder(\"float\", [None, num_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8dc9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Weights\"):\n",
    "    weights = {\n",
    "        'w1': tf.Variable(tf.truncated_normal([num_input, num_hidden1], stddev = 0.1), name = 'weights_1'),\n",
    "        'w2': tf.Variable(tf.truncated_normal([num_hidden1, num_hidden2], stddev = 0.1), name = 'weights_2'),\n",
    "        'w3': tf.Variable(tf.truncated_normal([num_hidden2, num_hidden3], stddev = 0.1), name = 'weights_3'),\n",
    "        'out': tf.Variable(tf.truncated_normal([num_hidden3, num_output], stddev = 0.1), name = 'weight_4')\n",
    "    }\n",
    "#truncated_normal : it is used to model the probabilities\n",
    "#of the binary outcomes in the probit model and to model censored data in the tobit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36bb8972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#biasing\n",
    "with tf.name_scope('biases'):\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.constant(0.1, shape=[num_hidden1]), name = 'bias_1'),\n",
    "        'b2': tf.Variable(tf.constant(0.1, shape=[num_hidden2]), name = 'bias_2'),\n",
    "        'b3': tf.Variable(tf.constant(0.1, shape=[num_hidden3]), name = 'bias_3'),\n",
    "        'out': tf.Variable(tf.constant(0.1, shape=[num_output]), name = 'bias_4'),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f666d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward propogation\n",
    "#we will use relu functions in all layers\n",
    "\n",
    "with tf.name_scope(\"Model\"):\n",
    "    with tf.name_scope(\"layer1\"):\n",
    "        layer_1 = tf.nn.relu(tf.add(tf.matmul(X, weights['w1']), biases['b1']))\n",
    "    with tf.name_scope(\"layer2\"):\n",
    "        layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1, weights['w2']), biases['b2']))\n",
    "    with tf.name_scope(\"layer3\"):\n",
    "        layer_3 = tf.nn.relu(tf.add(tf.matmul(layer_2, weights['w3']), biases['b3']))\n",
    "    with tf.name_scope(\"output\"):\n",
    "        y_hat = tf.nn.relu(tf.add(tf.matmul(layer_3, weights['out']), biases['out']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4784c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#backpropogation\n",
    "with tf.name_scope(\"Loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y_hat, labels = Y))\n",
    "learning_rate = 1e-4\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9c7c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy\n",
    "with tf.name_scope(\"Accuracy\"):\n",
    "    predicted_digit = tf.argmax(y_hat, 1)\n",
    "    actual_digit = tf.argmax(Y, 1)\n",
    "    correct_pred = tf.equal(predicted_digit, actual_digit)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dec3420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary\n",
    "tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "tf.summary.scalar(\"Loss\", loss)\n",
    "merge_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8baf636f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 20:40:56.105319: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-30 20:40:56.106136: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Loss:2.453235149383545\n",
      "Iteration: 100, Loss:0.5007684826850891\n",
      "Iteration: 200, Loss:0.45440128445625305\n",
      "Iteration: 300, Loss:0.3276500701904297\n",
      "Iteration: 400, Loss:0.2402748316526413\n",
      "Iteration: 500, Loss:0.25702691078186035\n",
      "Iteration: 600, Loss:0.18414843082427979\n",
      "Iteration: 700, Loss:0.11836256086826324\n",
      "Iteration: 800, Loss:0.1970120668411255\n",
      "Iteration: 900, Loss:0.0916593074798584\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "init = tf.global_variables_initializer()\n",
    "learning_rate = 1e-4\n",
    "num_iterations = 1000\n",
    "batch_size = 128\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    summary_writer = tf.summary.FileWriter('./graphs', graph = sess.graph)\n",
    "    for i in range(num_iterations):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        sess.run(optimizer, feed_dict= { X: batch_x, Y:batch_y})\n",
    "        if i % 100 == 0:\n",
    "            batch_loss, batch_accuracy, summary = sess.run([loss, accuracy, merge_summary], feed_dict={ X: batch_x, Y:batch_y})\n",
    "            summary_writer.add_summary(summary,i)\n",
    "            print('Iteration: {}, Loss:{}'.format(i, batch_loss,batch_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e140f6df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
